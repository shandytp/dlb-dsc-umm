{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materi Random Forest dan XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "Random Forest bisa dipakai untuk **Classification** dan **Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest adalah kombinasi dari masing - masing tree / pohon dan random. Gabungan dari *simplicity* Decision Tree tapi punya fleksibilitas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrap + Aggregating)\n",
    "\n",
    "Gampangannya kita ambil random sample\n",
    "\n",
    "![RandomForestURL](https://miro.medium.com/max/1000/1*Vv6AKoVfXtXs57Yzxd-ZXA.png \"random forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BootstrapURL](https://miro.medium.com/max/541/1*Qmx6upsk3bxIbdJr8y2aDA.png 'kerja')\n",
    "\n",
    "nanti output akhir nya bakal di aggregate atau voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogi\n",
    "\n",
    "Budi ingin jalan - jalan ke Jepang bulan depan, dia tanya ke teman - temannya untuk menanyakan rekomendasi tempat berlibur kalau mau ke Jepang. Dari jawaban itu akan dijadikan rekomendasi untuk tujuan lokasi jalan - jalannya. Tentu saja Budi tidak hanya tanya ke satu teman saja, pasti dia akan tanya ke teman - teman yang lainnya untuk mendapatkan rekomendasi tempat untuk berlibur di Jepang. Akhirnya Budi akan ke tempat berlibur itu berdasarkan rekomendasi dari teman - temannya. Kurang lebih seperti itulah Random Forest Approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree bad??\n",
    "\n",
    "Bisa jadi, karena Decision Tree itu rule itu terlalu fit(?) atau terlalu spesifik. Jadi kalau ada dataset yang berbeda bakal bingung algoritma nya. Performa nya bagus kalo pake dataset yang udah ada\n",
    "\n",
    "Atau gampangannya Decision Tree performa nya bagus kalo untuk training, tapi tidak fleksibel untuk melakukan prediksi pada unseen samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kan bisa bikin Decision Tree lebih dari satu\n",
    "\n",
    "ribet... wkwk\n",
    "\n",
    "Tujuan utama dari dibuatnya model Machine Learning ini adalah untuk melakukan generalisasi terhadap data baru yang belum pernah dilihat oleh algoritma kita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Random Forest?\n",
    "\n",
    "- Banyak variasinya dan terhindar dari overfitting, karena Decision Tree rule nya \"terlalu kaku\" \n",
    "- Bisa digunakan apabila kita memiliki unseen dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perbedaan Random Forest dan Decision Tree\n",
    "\n",
    "- Random Forest lebih fleksibel daripada Decision Tree\n",
    "- Decision Tree algoritmanya terlalu bias / overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TL;DR\n",
    "\n",
    "Random Forest itu seperti Decision Tree, tapi lebih banyak variancenya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OverfitURL](https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/Screenshot-2020-02-06-at-11.09.13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:37:03.169052Z",
     "start_time": "2021-01-16T12:37:03.153143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:37:04.084054Z",
     "start_time": "2021-01-16T12:37:04.006026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:37:11.515391Z",
     "start_time": "2021-01-16T12:37:11.508411Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:37:16.100007Z",
     "start_time": "2021-01-16T12:37:16.094029Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:37:17.731243Z",
     "start_time": "2021-01-16T12:37:17.725236Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Species'], axis=1)\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:37:21.675882Z",
     "start_time": "2021-01-16T12:37:21.664890Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:38:08.988275Z",
     "start_time": "2021-01-16T12:38:08.754756Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:38:16.862795Z",
     "start_time": "2021-01-16T12:38:16.853774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:39:44.237296Z",
     "start_time": "2021-01-16T12:39:44.216293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg = pd.read_csv('petrol_consumption.csv')\n",
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:40:07.355378Z",
     "start_time": "2021-01-16T12:40:07.347403Z"
    }
   },
   "outputs": [],
   "source": [
    "X_reg = df_reg.drop(['Petrol_Consumption'], axis=1)\n",
    "y_reg = df_reg['Petrol_Consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:40:07.730342Z",
     "start_time": "2021-01-16T12:40:07.723339Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:04:06.153699Z",
     "start_time": "2021-01-16T10:04:06.141716Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Harus di Feature Scaling karena range value dari masing masing kolom terlalu lebar\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_reg = sc.fit_transform(X_train_reg)\n",
    "X_test_reg = sc.transform(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:41:46.638445Z",
     "start_time": "2021-01-16T12:41:46.592325Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = regressor.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T12:41:47.124548Z",
     "start_time": "2021-01-16T12:41:47.114513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 52.36500000000001\n",
      "Mean Squared Error: 4916.644249999999\n",
      "Root Mean Squared Error: 70.11878671226421\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_reg, y_pred_reg))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test_reg, y_pred_reg))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test_reg, y_pred_reg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "Cara install nya\n",
    "\n",
    "`pip install xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "XGBoost merupakan singkatan dari **eXtreme Gradient Boosting** yang di develop oleh Tianqi Chen. Seperti Random Forest, juga bisa melakukan **Classification** dan **Regression**. Base nya menggunakan **Gradient Boosting**.\n",
    "\n",
    "Kalau kalian tertarik apa itu **Gradient Boosting** bisa liat referensi dibawah ini:\n",
    "\n",
    "- [Boosting](https://youtu.be/MIPkK5ZAsms)\n",
    "- [XGBoost Mathematics Explained](https://towardsdatascience.com/xgboost-mathematics-explained-58262530904a)\n",
    "- [XGBoost Two Minutes Paper](https://www.youtube.com/watch?v=0Xc9LIb_HTw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagaimana cara kerjanya?\n",
    "\n",
    "Jadi ada model Tree yang lemah / shallow / pendek, itu kita *boosting* agar performanya bagus.\n",
    "\n",
    "Gampangannya model Tree kita kasih steroid / \"cheat\" biar performa nya bagus, dari yang weak learners menjadi strong learners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Tree Model?\n",
    "\n",
    "![XGBoostURL](https://image.slidesharecdn.com/rg-xgboost-20170306-170314022553/95/introduction-to-xgboost-10-638.jpg?cb=1489458437)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DecisionTreeWeak](https://glints.com/id/lowongan/wp-content/uploads/2020/11/Zrzut-ekranu-2020-04-28-o-14.18.08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why XGBoost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Bisa handle missing values automatically, tapi tidak semua data bisa di handle. seperti categorical data tidak bisa langsung di handle, harus di encode terlebih dahulu\n",
    "- Karena *parallel processing* jadi bisa handle dataset yg besar\n",
    "- Speed and performance, karena ditulis dengan bahasa pemrogramman C++\n",
    "- Hyperparameter Tuning. Parameter nya ada buanyak sekali, jadi kita bisa tuning sesuka kita.\n",
    "\n",
    "Kalau mau baca dokumentasi XGBoost buat parameter yang ada. [Parameter](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perbedaan XGBoost dan Random Forest\n",
    "\n",
    "- XGBoost digunakan berdasarkan **weak** learners (high bias, low variance).\n",
    "- Random Forest digunakan pada Decision Tree yang \"rimbun\" (low bias, high variance).\n",
    "\n",
    "[Referensi](https://stats.stackexchange.com/questions/173390/gradient-boosting-tree-vs-random-forest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:40.745915Z",
     "start_time": "2021-01-16T13:08:40.737920Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing dataset from sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "iris = datasets.load_iris() #dataset loading\n",
    "X = iris.data               #Features stored in X \n",
    "y = iris.target             #Class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:40.925087Z",
     "start_time": "2021-01-16T13:08:40.920088Z"
    }
   },
   "outputs": [],
   "source": [
    "#Splitting dataset into Training (80%) and testing data (20%) using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_baru, X_test_baru, y_train_baru, y_test_baru = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:42.487948Z",
     "start_time": "2021-01-16T13:08:42.477981Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_baru, label=y_train_baru)\n",
    "dtest = xgb.DMatrix(X_test_baru, label=y_test_baru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:45.970636Z",
     "start_time": "2021-01-16T13:08:45.965619Z"
    }
   },
   "outputs": [],
   "source": [
    "#paramaters \n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'objective': 'multi:softmax',  # fungsi aktivasi nya, disesuaikan dengan studi kasusnya\n",
    "    'num_class': 3}  # banyak kelas nya, juga disesuaikan dengan studi kasusnya\n",
    "epochs = 10  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:47.309456Z",
     "start_time": "2021-01-16T13:08:47.285939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#model builing using training data\n",
    "bst = xgb.train(param, dtrain, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:47.775798Z",
     "start_time": "2021-01-16T13:08:47.771794Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:48.140000Z",
     "start_time": "2021-01-16T13:08:48.133002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 2. 1. 2. 0. 0. 2. 1. 0. 2. 1. 1. 0. 1. 1. 0. 0. 1. 1. 2. 0.\n",
      " 2. 1. 0. 0. 1. 2. 1. 2. 1. 2. 2. 0. 1. 0. 1. 2. 2. 0. 2. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T13:08:49.344737Z",
     "start_time": "2021-01-16T13:08:49.336725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_test_baru, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referensi Belajar\n",
    "\n",
    "- [Datacamp](datacamp.com)\n",
    "- Youtube : [StatQuest with Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:50:22.323271Z",
     "start_time": "2021-01-16T10:50:22.318271Z"
    }
   },
   "source": [
    "### Contact Me\n",
    "\n",
    "- Email = shandytsalasa@gmail.com\n",
    "- Telegram = @shandytp\n",
    "- Github = https://github.com/shandytp\n",
    "- Linkedin = https://www.linkedin.com/in/moch-shandy-tsalasa-putra-5a0b721aa/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sandbox)",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
